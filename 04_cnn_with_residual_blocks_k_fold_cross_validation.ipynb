{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371229ca",
   "metadata": {},
   "source": [
    "# The CNN With Residual Blocks Model k-fold Cross Validation\n",
    "\n",
    "CHEST X-RAY IMAGES CLASSIFICATION WITH CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133e58e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.10.0\n",
      "numpy version: 1.23.4\n",
      "pandas version: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os, shutil, pathlib\n",
    "\n",
    "\n",
    "print(\"tensorflow version:\", tf.__version__)\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"pandas version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c545e",
   "metadata": {},
   "source": [
    "## Paths of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198049bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/20210708_g√∂r√ºnt√ºler'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"../data\"\n",
    "RAW_DATASET_NAME = \"20210708_g√∂r√ºnt√ºler\"   # raw dataset folder name\n",
    "SUB_FOLDERS_PATH = f\"{DATA_PATH}/{RAW_DATASET_NAME}\"  # sub class folders\n",
    "\n",
    "SUB_FOLDERS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4016f06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20210708_g√∂r√ºnt√ºler', 'images_1', 'manuel_differet_person']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "679c3869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covid+ ac grafileri': 'covid',\n",
       " 'infiltratif akciƒüer hastasƒ± grafileri': 'infiltiratif',\n",
       " 'normal akciƒüer grafileri': 'normal'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {\"covid+ ac grafileri\" : \"covid\",\n",
    "         \"infiltratif akciƒüer hastasƒ± grafileri\" : \"infiltiratif\",\n",
    "         \"normal akciƒüer grafileri\": \"normal\"}\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f013e1a5",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a731c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_for_folders(DATA_PATH, DATASET_NAME, labels):\n",
    "    \"\"\"create dataframe from data folders that every folder has one class data\n",
    "    \n",
    "    It prepares dataframe to put in  TF flow_from_dataframe function\n",
    "    \n",
    "    Args:\n",
    "        DATA_PATH : parent folder relative path of DATASET_NAME. It contains all of data files.\n",
    "        DATASET_NAME : dataset name which wanted to use - path from DATA_PATH to classes folders\n",
    "        labels: a dict that contains folder names according to classes\n",
    "        \n",
    "    Returns:\n",
    "        A pandas dataframe that has relative path to the dataset_name of data and labels\n",
    "    \"\"\"\n",
    "    CLASS_FOLDERS_PATHS = os.listdir(f\"{DATA_PATH}/{DATASET_NAME}\")\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"path\", \"label\"])  # empty dataframe\n",
    "    \n",
    "    for i in CLASS_FOLDERS_PATHS:\n",
    "        # list files - images\n",
    "        list_of_files = os.listdir(f\"{DATASET_NAME}/{i}\")\n",
    "        \n",
    "        for k, name in enumerate(list_of_files):\n",
    "            list_of_files[k] = f\"{i}/\"+name       # add parent folder\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(list_of_files, columns=[\"path\"])], ignore_index=True)\n",
    "        df.fillna(labels[i], inplace=True)  # label column is NaN, so we put labels every iteration. because every folder has one class        \n",
    "    \n",
    "#     df.reset_index(inplace = True)  \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58d4b93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 336 entries, 0 to 335\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   path    336 non-null    object\n",
      " 1   label   336 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2f56c",
   "metadata": {},
   "source": [
    "# New CNN with Residual Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dc5173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc754f",
   "metadata": {},
   "source": [
    "## Identity Block\n",
    "`The identity block is a slightly different and more powerful version of the standard block used in ResNets, and corresponds to the case where the input activation (say ùëé[ùëô]) has the same dimension as the output activation (say ùëé[ùëô+2]).`\n",
    "\n",
    "[Source: Convolutional Neural Networks on Coursera by Andrew NG](https://www.coursera.org/learn/convolutional-neural-networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf371470",
   "metadata": {},
   "source": [
    "<img src=\"images/idblock3_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "    <caption><center> <u> <font color='purple'> <b>Figure 1</b> </u><font color='purple'>  : <b>Identity block.</b> Skip connection \"skips over\" 3 layers.</center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b62baefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 1\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ## Second component of main path (‚âà3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = f, strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ## Third component of main path (‚âà2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) \n",
    "    \n",
    "    ## Final step:\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505d1f1a",
   "metadata": {},
   "source": [
    "## The Convolutional Block \n",
    "`The ResNet \"convolutional block\" is the second block type. You can use this type of block when the input and output dimensions don't match up.`\n",
    "\n",
    "[Source: Convolutional Neural Networks on Coursera by Andrew NG](https://www.coursera.org/learn/convolutional-neural-networks)\n",
    "\n",
    "<img src=\"images/convblock_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 2</b> </u><font color='purple'>  : <b>Convolutional block</b> </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63404780",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n",
    "                   also called Xavier uniform initializer.\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    \n",
    "    # First component of main path glorot_uniform(seed=0)\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ## Second component of main path (‚âà3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = f, strides = (1, 1), padding = 'same', kernel_initializer = initializer(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training) \n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ## Third component of main path (‚âà2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    \n",
    "    ##### SHORTCUT PATH ##### (‚âà2 lines)\n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s,s), padding = 'valid', kernel_initializer = initializer(seed = 0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training=training)\n",
    "\n",
    "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf0329",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0f4edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d55a9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 480\n",
    "height = 480\n",
    "\n",
    "input_size = (width, height)\n",
    "input_shape = (width, height,3)\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "val_batch_size = 4\n",
    "test_batch_size = 4\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = layers.Conv2D(64, 3, strides=2, padding=\"same\", use_bias=False)(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 128], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 128])\n",
    "    X = identity_block(X, 3, [64, 64, 128])\n",
    "    \n",
    "    #### NEW Layers\n",
    "    for size in [32, 64, 128]:\n",
    "\n",
    "        X = layers.BatchNormalization()(X)\n",
    "        X = layers.Activation(\"relu\")(X)\n",
    "\n",
    "        X = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(X)\n",
    "        X = layers.BatchNormalization()(X)\n",
    "        X = layers.Activation(\"relu\")(X)\n",
    "\n",
    "        X = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(X)\n",
    "        X = layers.MaxPooling2D(3, strides=2, padding=\"same\")(X)\n",
    "        \n",
    "        X = layers.Conv2D(size, 3, strides=2, padding=\"same\", use_bias=False)(X)\n",
    "        X = layers.BatchNormalization()(X)\n",
    "\n",
    "\n",
    "    ## AVGPOOL\n",
    "    X = AveragePooling2D(pool_size = (2, 2))(X)\n",
    "\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    X = layers.Dropout(0.5)(X)\n",
    "    X = layers.Dense(64, activation=\"relu\")(X)\n",
    "    X = layers.Dropout(0.5)(X)\n",
    "    \n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3a1c65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 480, 3)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 480, 480, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 486, 486, 3)  0          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 240, 240, 64  9472        ['zero_padding2d[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 240, 240, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 120, 120, 64  36864       ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 120, 120, 64  256        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 120, 120, 64  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 120, 120, 64  4160        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 120, 120, 64  256        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 120, 120, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 120, 120, 64  36928       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 120, 120, 64  256        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 120, 120, 64  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 120, 120, 12  8320        ['activation_2[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 120, 120, 12  8320        ['activation[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 120, 120, 12  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 120, 120, 12  512        ['conv2d_5[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 120, 120, 12  0           ['batch_normalization_4[0][0]',  \n",
      "                                8)                                'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 120, 120, 12  0           ['add[0][0]']                    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 120, 120, 64  8256        ['activation_3[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 120, 120, 64  256        ['conv2d_6[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 120, 120, 64  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 120, 120, 64  36928       ['activation_4[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 120, 120, 64  256        ['conv2d_7[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 120, 120, 64  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 120, 120, 12  8320        ['activation_5[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 120, 120, 12  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " add_1 (Add)                    (None, 120, 120, 12  0           ['activation_3[0][0]',           \n",
      "                                8)                                'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 120, 120, 12  0           ['add_1[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 120, 120, 64  8256        ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 120, 120, 64  256        ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 120, 120, 64  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 120, 120, 64  36928       ['activation_7[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 120, 120, 64  256        ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 120, 120, 64  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 120, 120, 12  8320        ['activation_8[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 120, 120, 12  512        ['conv2d_11[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 120, 120, 12  0           ['activation_6[0][0]',           \n",
      "                                8)                                'batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 120, 120, 12  0           ['add_2[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 120, 120, 12  512        ['activation_9[0][0]']           \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 120, 120, 12  0           ['batch_normalization_12[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " separable_conv2d (SeparableCon  (None, 120, 120, 32  5248       ['activation_10[0][0]']          \n",
      " v2D)                           )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 120, 120, 32  128        ['separable_conv2d[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 120, 120, 32  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_1 (SeparableC  (None, 120, 120, 32  1312       ['activation_11[0][0]']          \n",
      " onv2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 60, 60, 32)   0           ['separable_conv2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 30, 30, 32)   9216        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 30, 30, 32)  128         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 30, 30, 32)  128         ['batch_normalization_14[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 30, 30, 32)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_2 (SeparableC  (None, 30, 30, 64)  2336        ['activation_12[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 30, 30, 64)  256         ['separable_conv2d_2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 30, 30, 64)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_3 (SeparableC  (None, 30, 30, 64)  4672        ['activation_13[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 15, 15, 64)  0           ['separable_conv2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 64)     36864       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 8, 8, 64)    256         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 8, 8, 64)    256         ['batch_normalization_17[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_4 (SeparableC  (None, 8, 8, 128)   8768        ['activation_14[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 8, 8, 128)   512         ['separable_conv2d_4[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " separable_conv2d_5 (SeparableC  (None, 8, 8, 128)   17536       ['activation_15[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 128)   0           ['separable_conv2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 2, 2, 128)    147456      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 2, 2, 128)   512         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 128)   0           ['batch_normalization_20[0][0]'] \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 128)          0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 3)            195         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 459,715\n",
      "Trainable params: 456,323\n",
      "Non-trainable params: 3,392\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(input_shape = input_shape, classes = 3)  # covid19 - infiltratrif - normal\n",
    "print(input_shape)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba07853",
   "metadata": {},
   "source": [
    "# K-fold Validation - 5 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb28b66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/20210708_g√∂r√ºnt√ºler'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUB_FOLDERS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0b7d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train_index:  268\n",
      "length of test_index:  68\n",
      "\n",
      "length of train_index:  269\n",
      "length of test_index:  67\n",
      "\n",
      "length of train_index:  269\n",
      "length of test_index:  67\n",
      "\n",
      "length of train_index:  269\n",
      "length of test_index:  67\n",
      "\n",
      "length of train_index:  269\n",
      "length of test_index:  67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stratified k-fold splits data for a percentage of samples for each class\n",
    "cv = StratifiedKFold(n_splits=5,shuffle=False)\n",
    "\n",
    "for train_index, test_index in cv.split(df, df.label):\n",
    "    print(\"length of train_index: \", len(train_index))\n",
    "    print(\"length of test_index: \", len(test_index))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c244161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "Initializing Kfold 0\n",
      "Train shape: (268, 2)\n",
      "Test shape: (68, 2)\n",
      "Found 268 validated image filenames belonging to 3 classes.\n",
      "Found 68 validated image filenames belonging to 3 classes.\n",
      "train_loss:  0.26112616062164307   train_accuracy 0.858208954334259\n",
      "val_loss:  0.3500613868236542   val_accuracy:  0.779411792755127\n",
      "\n",
      "-----------------------------\n",
      "Initializing Kfold 1\n",
      "Train shape: (269, 2)\n",
      "Test shape: (67, 2)\n",
      "Found 269 validated image filenames belonging to 3 classes.\n",
      "Found 67 validated image filenames belonging to 3 classes.\n",
      "train_loss:  0.2243489772081375   train_accuracy 0.9070631861686707\n",
      "val_loss:  0.3747405409812927   val_accuracy:  0.8507462739944458\n",
      "\n",
      "-----------------------------\n",
      "Initializing Kfold 2\n",
      "Train shape: (269, 2)\n",
      "Test shape: (67, 2)\n",
      "Found 269 validated image filenames belonging to 3 classes.\n",
      "Found 67 validated image filenames belonging to 3 classes.\n",
      "train_loss:  0.20278391242027283   train_accuracy 0.9033457040786743\n",
      "val_loss:  0.4836575388908386   val_accuracy:  0.8358209133148193\n",
      "\n",
      "-----------------------------\n",
      "Initializing Kfold 3\n",
      "Train shape: (269, 2)\n",
      "Test shape: (67, 2)\n",
      "Found 269 validated image filenames belonging to 3 classes.\n",
      "Found 67 validated image filenames belonging to 3 classes.\n",
      "train_loss:  0.248245969414711   train_accuracy 0.8661710023880005\n",
      "val_loss:  0.4643632173538208   val_accuracy:  0.8507462739944458\n",
      "\n",
      "-----------------------------\n",
      "Initializing Kfold 4\n",
      "Train shape: (269, 2)\n",
      "Test shape: (67, 2)\n",
      "Found 269 validated image filenames belonging to 3 classes.\n",
      "Found 67 validated image filenames belonging to 3 classes.\n",
      "train_loss:  0.24331004917621613   train_accuracy 0.8773234486579895\n",
      "val_loss:  0.23099426925182343   val_accuracy:  0.9253731369972229\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "\n",
    "all_train_scores = []   # all train scores on k-fold test data\n",
    "all_val_scores = []   # all validation scores on k-fold test data\n",
    "\n",
    "\n",
    "for train_index, test_index in cv.split(df, df.label):\n",
    "    \n",
    "    df_train = df.iloc[train_index]\n",
    "    df_test = df.iloc[test_index]\n",
    "    \n",
    "    print(\"\\n-----------------------------\")\n",
    "    print('Initializing Kfold %s'%str(k))\n",
    "    print('Train shape:', df_train.shape)\n",
    "    print('Test shape:', df_test.shape)\n",
    "    \n",
    "\n",
    "    \n",
    "    # rescaling was not used because rescaling was used in model layers.    \n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "\n",
    "    train_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                                directory=SUB_FOLDERS_PATH,\n",
    "                                                x_col=\"path\",\n",
    "                                                y_col=\"label\",\n",
    "                                                batch_size=batch_size,\n",
    "                                                seed=42,\n",
    "                                                shuffle=True,\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                target_size=input_size)\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_dataframe(dataframe=df_test,\n",
    "                                                directory=SUB_FOLDERS_PATH,\n",
    "                                                x_col=\"path\",\n",
    "                                                y_col=\"label\",\n",
    "                                                batch_size=val_batch_size,\n",
    "                                                seed=42,\n",
    "                                                shuffle=True,\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                target_size=input_size)\n",
    "    \n",
    "    model = ResNet50(input_shape = input_shape, classes = 3)\n",
    "    model.fit(train_generator, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    train_generator.reset()\n",
    "    train_loss, train_accuracy = model.evaluate(train_generator, verbose=0)\n",
    "    print(\"train_loss: \", train_loss, \"  train_accuracy\", train_accuracy)\n",
    "    all_train_scores.append(train_accuracy)\n",
    "    \n",
    "    validation_generator.reset()\n",
    "    val_loss, val_accuracy = model.evaluate(validation_generator, verbose=0)\n",
    "    print(\"val_loss: \", val_loss, \"  val_accuracy: \", val_accuracy)\n",
    "    all_val_scores.append(val_accuracy)\n",
    "    \n",
    "    k+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "326f8213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All train scores:  [0.858208954334259, 0.9070631861686707, 0.9033457040786743, 0.8661710023880005, 0.8773234486579895]\n",
      "\n",
      "Mean of all train scores:  0.8824224591255188\n",
      "\n",
      "All validation scores:  [0.779411792755127, 0.8507462739944458, 0.8358209133148193, 0.8507462739944458, 0.9253731369972229]\n",
      "\n",
      "Mean of all validation scores:  0.8484196782112121\n"
     ]
    }
   ],
   "source": [
    "print(\"All train scores: \", all_train_scores)\n",
    "print(\"\\nMean of all train scores: \", np.mean(all_train_scores))\n",
    "print(\"\\nAll validation scores: \", all_val_scores)\n",
    "print(\"\\nMean of all validation scores: \", np.mean(all_val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38e87adb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All train scores:  [0.858208954334259, 0.9070631861686707, 0.9033457040786743, 0.8661710023880005, 0.8773234486579895]\n",
      "\n",
      "Mean of all train scores:  0.8824224591255188\n",
      "\n",
      "All validation scores:  [0.779411792755127, 0.8507462739944458, 0.8358209133148193, 0.8507462739944458, 0.9253731369972229]\n",
      "\n",
      "Mean of all validation scores:  0.8484196782112121\n"
     ]
    }
   ],
   "source": [
    "print(\"All train scores: \", all_train_scores)\n",
    "print(\"\\nMean of all train scores: \", np.mean(all_train_scores))\n",
    "print(\"\\nAll validation scores: \", all_val_scores)\n",
    "print(\"\\nMean of all validation scores: \", np.mean(all_val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41d326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812c8fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab421175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
